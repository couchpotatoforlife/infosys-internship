# -*- coding: utf-8 -*-
"""assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-VBKofrXBLGD9bBYL6psoiuYrAWEPufw
"""



import pandas as pd
import numpy as np

np.random.seed(123)

# Generate numerical columns with NaN values
num1 = np.random.randn(500)
num2 = np.random.uniform(10, 50, size=500)
num3 = np.random.randint(1, 6, size=500).astype('float')
num1[np.random.choice(500, 60, replace=False)] = np.nan
num2[np.random.choice(500, 60, replace=False)] = np.nan
num3[np.random.choice(500, 60, replace=False)] = np.nan

# Generate messy categorical/text columns
cat1 = np.random.choice(['apple', 'banana', 'grape', np.nan], size=500, p=[0.3, 0.3, 0.3, 0.1])
cat2 = np.random.choice(['A', 'B', 'C', 'D'], size=500)
cat3 = np.random.choice(['Yes', 'No', np.nan], size=500, p=[0.45, 0.45, 0.10])

# Combine into DataFrame and add untidiness
df_untidy = pd.DataFrame({
    'Score': num1,
    'Height_cm': num2,
    'Rating': num3,
    'Fruit': cat1,
    'Group': cat2,
    'IsActive': cat3
})

# Add untidy issues:
df_untidy.loc[df_untidy.sample(frac=0.15, random_state=1).index, 'Height_cm'] = \
    df_untidy['Height_cm'].dropna().astype(str) + 'cm'   # Mix data type in Height_cm

df_untidy.loc[df_untidy.sample(frac=0.15, random_state=2).index, 'Rating'] = \
    'Rating: ' + df_untidy['Rating'].dropna().astype(str) # Prefix string for some ratings

df_untidy.head()

#1.Q1. Identify columns with missing values and demonstrate at least two methods for imputing or filling these missing values (e.g., mean for numerics, mode for categoricals).
print("Missing values before imputation:")
print(df_untidy.isnull().sum())

df_q1 = df_untidy.copy()
df_q1['Score'] = df_q1['Score'].fillna(df_q1['Score'].mean())
df_q1['Height_cm'] = df_q1['Height_cm'].fillna(df_q1['Height_cm'].mode()[0])
df_q1['Rating'] = df_q1['Rating'].fillna(df_q1['Rating'].mode()[0])
df_q1['Fruit'] = df_q1['Fruit'].fillna(df_q1['Fruit'].mode()[0])
df_q1['IsActive'] = df_q1['IsActive'].fillna('Unknown')
print("\nMissing values after imputation:")
print(df_q1.isnull().sum())

#  Q2. Encode Categorical Columns
from sklearn.preprocessing import LabelEncoder
df_q2 = df_q1.copy()
le = LabelEncoder()
df_q2['IsActive'] = le.fit_transform(df_q2['IsActive'].astype(str))
df_q2 = pd.get_dummies(df_q2, columns=['Group', 'Fruit'], drop_first=True)
# Show the first few rows after encoding
print(df_q2.head())

#Q3. Detect and Fix Mixed Data Types
df_q3 = df_untidy.copy()

print("Columns with object/mixed types before cleaning:")
print(df_q3.select_dtypes(include='object').columns.tolist())
df_q3['Height_cm'] = df_q3['Height_cm'].astype(str).str.replace('cm', '', regex=True)
df_q3['Height_cm'] = pd.to_numeric(df_q3['Height_cm'], errors='coerce')

df_q3['Rating'] = df_q3['Rating'].astype(str).str.replace('Rating: ', '', regex=True)
df_q3['Rating'] = pd.to_numeric(df_q3['Rating'], errors='coerce')

print("\nData types after cleaning:")
print(df_q3.dtypes)

print("\nPreview of cleaned columns:")
print(df_q3[['Height_cm', 'Rating']].head(10))

# ---------------- Q4. Apply Scaling & Normalization ----------------
from sklearn.preprocessing import MinMaxScaler, StandardScaler

df_q4 = df_q3.copy()
num_cols = ['Score', 'Height_cm', 'Rating']

scaler_minmax = MinMaxScaler()
df_q4[[col + "_minmax" for col in num_cols]] = scaler_minmax.fit_transform(df_q4[num_cols])

scaler_std = StandardScaler()
df_q4[[col + "_std" for col in num_cols]] = scaler_std.fit_transform(df_q4[num_cols])

print("Scaled columns added:")
print(df_q4.head()[[col + "_minmax" for col in num_cols] + [col + "_std" for col in num_cols]])

# ---------------- Q5. Validation Function ----------------
def validate_dataframe(df):
    report = {}
    report['missing_values'] = df.isnull().sum().to_dict()
    report['object_columns'] = df.select_dtypes(include='object').columns.tolist()
    if 'Rating' in df.columns:
        out_of_range = df[(df['Rating'] < 1) | (df['Rating'] > 5)]
        report['rating_out_of_range_count'] = len(out_of_range)
    return report

final_report = validate_dataframe(df_q4)
print("\nValidation Report:")
print(final_report)
print("\nCleaned DataFrame Preview:")
print(df_q4.head())